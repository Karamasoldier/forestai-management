# -*- coding: utf-8 -*-
"""
Gestionnaire des performances des opérateurs forestiers.

Ce module contient les fonctions de gestion des évaluations de performance
pour les opérateurs et les opérations forestières.
"""

import json
import uuid
import logging
import os
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime, timedelta
from pathlib import Path
import statistics

from forestai.core.utils.logging_utils import get_logger
from forestai.agents.exploitant_agent.models.performance_models import (
    PerformanceEvaluation, PerformanceCriteria, ScoreEntry,
    OperatorPerformanceSummary, PerformanceReport
)

logger = get_logger(__name__)

class PerformanceManager:
    """
    Gestionnaire des performances des opérateurs forestiers.
    
    Cette classe fournit les méthodes pour créer et récupérer des évaluations de performance,
    ainsi que pour générer des rapports et des analyses de tendances.
    """
    
    def __init__(self, data_dir: Optional[Path] = None):
        """
        Initialise le gestionnaire des performances.
        
        Args:
            data_dir: Répertoire de stockage des données (facultatif)
        """
        # Si aucun répertoire n'est spécifié, utiliser le dossier par défaut
        if data_dir is None:
            data_dir = Path(os.environ.get("FORESTAI_DATA_DIR", ".")) / "data" / "performances"
        
        self.data_dir = data_dir
        self.evaluations_file = self.data_dir / "evaluations.json"
        self.reports_file = self.data_dir / "reports.json"
        
        # Créer le répertoire si nécessaire
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # Charger les évaluations et rapports existants
        self.evaluations = self._load_evaluations()
        self.reports = self._load_reports()
        
        logger.info(f"PerformanceManager initialisé avec {len(self.evaluations)} évaluations et {len(self.reports)} rapports")
    
    def _load_evaluations(self) -> Dict[str, PerformanceEvaluation]:
        """
        Charge les évaluations à partir du fichier de stockage.
        
        Returns:
            Dictionnaire des évaluations indexées par leur identifiant
        """
        evaluations = {}
        
        # Si le fichier existe, charger les données
        if self.evaluations_file.exists():
            try:
                with open(self.evaluations_file, 'r', encoding='utf-8') as f:
                    evaluations_data = json.load(f)
                
                for evaluation_data in evaluations_data:
                    try:
                        evaluation = PerformanceEvaluation.from_dict(evaluation_data)
                        evaluations[evaluation.id] = evaluation
                    except Exception as e:
                        logger.error(f"Erreur lors du chargement de l'évaluation: {str(e)}")
                        
            except Exception as e:
                logger.error(f"Erreur lors du chargement des évaluations: {str(e)}")
        
        return evaluations
    
    def _save_evaluations(self) -> bool:
        """
        Sauvegarde les évaluations dans le fichier de stockage.
        
        Returns:
            True si la sauvegarde a réussi, False sinon
        """
        try:
            evaluations_data = [evaluation.to_dict() for evaluation in self.evaluations.values()]
            
            with open(self.evaluations_file, 'w', encoding='utf-8') as f:
                json.dump(evaluations_data, f, ensure_ascii=False, indent=2)
                
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde des évaluations: {str(e)}")
            return False
    
    def _load_reports(self) -> Dict[str, PerformanceReport]:
        """
        Charge les rapports à partir du fichier de stockage.
        
        Returns:
            Dictionnaire des rapports indexés par leur identifiant
        """
        reports = {}
        
        # Si le fichier existe, charger les données
        if self.reports_file.exists():
            try:
                with open(self.reports_file, 'r', encoding='utf-8') as f:
                    reports_data = json.load(f)
                
                for report_data in reports_data:
                    try:
                        report = PerformanceReport.from_dict(report_data)
                        reports[report.id] = report
                    except Exception as e:
                        logger.error(f"Erreur lors du chargement du rapport: {str(e)}")
                        
            except Exception as e:
                logger.error(f"Erreur lors du chargement des rapports: {str(e)}")
        
        return reports
    
    def _save_reports(self) -> bool:
        """
        Sauvegarde les rapports dans le fichier de stockage.
        
        Returns:
            True si la sauvegarde a réussi, False sinon
        """
        try:
            reports_data = [report.to_dict() for report in self.reports.values()]
            
            with open(self.reports_file, 'w', encoding='utf-8') as f:
                json.dump(reports_data, f, ensure_ascii=False, indent=2)
                
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde des rapports: {str(e)}")
            return False
    
    def get_evaluations(self, filters: Optional[Dict[str, Any]] = None) -> List[PerformanceEvaluation]:
        """
        Récupère les évaluations selon les filtres spécifiés.
        
        Args:
            filters: Filtres à appliquer (facultatif)
            
        Returns:
            Liste des évaluations correspondant aux filtres
        """
        if not filters:
            # Retourner toutes les évaluations
            return list(self.evaluations.values())
        
        result = []
        
        for evaluation in self.evaluations.values():
            # Appliquer les filtres
            match = True
            
            # Filtre par opérateur
            if "operator_id" in filters and filters["operator_id"]:
                if evaluation.operator_id != filters["operator_id"]:
                    match = False
            
            # Filtre par opération
            if "operation_id" in filters and filters["operation_id"]:
                if evaluation.operation_id != filters["operation_id"]:
                    match = False
            
            # Filtre par date d'évaluation (après)
            if "evaluated_after" in filters and filters["evaluated_after"]:
                evaluated_after = filters["evaluated_after"]
                if isinstance(evaluated_after, str):
                    evaluated_after = datetime.fromisoformat(evaluated_after.replace("Z", "+00:00"))
                
                if evaluation.evaluated_at < evaluated_after:
                    match = False
            
            # Filtre par date d'évaluation (avant)
            if "evaluated_before" in filters and filters["evaluated_before"]:
                evaluated_before = filters["evaluated_before"]
                if isinstance(evaluated_before, str):
                    evaluated_before = datetime.fromisoformat(evaluated_before.replace("Z", "+00:00"))
                
                if evaluation.evaluated_at > evaluated_before:
                    match = False
            
            # Filtre par score minimal
            if "min_score" in filters and filters["min_score"] is not None:
                min_score = float(filters["min_score"])
                if evaluation.overall_score is None or evaluation.overall_score < min_score:
                    match = False
            
            # Filtre par évaluateur
            if "evaluator" in filters and filters["evaluator"]:
                if not evaluation.evaluator or filters["evaluator"].lower() not in evaluation.evaluator.lower():
                    match = False
            
            # Ajouter l'évaluation si elle correspond aux filtres
            if match:
                result.append(evaluation)
        
        return result
    
    def get_evaluation(self, evaluation_id: str) -> Optional[PerformanceEvaluation]:
        """
        Récupère une évaluation par son identifiant.
        
        Args:
            evaluation_id: Identifiant de l'évaluation
            
        Returns:
            Évaluation correspondante ou None si elle n'existe pas
        """
        return self.evaluations.get(evaluation_id)
    
    def add_evaluation(self, evaluation_data: Dict[str, Any]) -> Optional[PerformanceEvaluation]:
        """
        Ajoute une nouvelle évaluation.
        
        Args:
            evaluation_data: Données de l'évaluation
            
        Returns:
            Nouvelle évaluation créée ou None en cas d'erreur
        """
        try:
            # Générer un identifiant unique
            evaluation_id = evaluation_data.get("id")
            if not evaluation_id:
                evaluation_id = f"eval-{uuid.uuid4().hex[:8]}"
                evaluation_data["id"] = evaluation_id
            
            # S'assurer que l'id n'existe pas déjà
            if evaluation_id in self.evaluations:
                logger.error(f"Une évaluation avec l'identifiant {evaluation_id} existe déjà")
                return None
            
            # Créer l'évaluation
            evaluation = PerformanceEvaluation.from_dict(evaluation_data)
            
            # Calculer le score global si nécessaire
            if evaluation.overall_score is None:
                evaluation.calculate_overall_score()
            
            # Ajouter l'évaluation à la collection
            self.evaluations[evaluation.id] = evaluation
            
            # Sauvegarder les changements
            self._save_evaluations()
            
            logger.info(f"Évaluation (ID: {evaluation.id}) ajoutée avec succès")
            return evaluation
            
        except Exception as e:
            logger.error(f"Erreur lors de l'ajout de l'évaluation: {str(e)}")
            return None
    
    def update_evaluation(self, evaluation_id: str, evaluation_data: Dict[str, Any]) -> Optional[PerformanceEvaluation]:
        """
        Met à jour une évaluation existante.
        
        Args:
            evaluation_id: Identifiant de l'évaluation à mettre à jour
            evaluation_data: Nouvelles données de l'évaluation
            
        Returns:
            Évaluation mise à jour ou None en cas d'erreur
        """
        # Vérifier que l'évaluation existe
        if evaluation_id not in self.evaluations:
            logger.error(f"Évaluation avec ID {evaluation_id} non trouvée")
            return None
        
        try:
            # Récupérer l'évaluation existante
            existing_evaluation = self.evaluations[evaluation_id]
            
            # Créer un dictionnaire avec les données existantes
            updated_data = existing_evaluation.to_dict()
            
            # Mettre à jour uniquement les champs fournis
            for key, value in evaluation_data.items():
                # Ignorer l'ID car on ne peut pas le changer
                if key != "id":
                    updated_data[key] = value
            
            # Créer l'évaluation mise à jour
            updated_evaluation = PerformanceEvaluation.from_dict(updated_data)
            
            # Recalculer le score global
            updated_evaluation.calculate_overall_score()
            
            # Mettre à jour l'évaluation dans la collection
            self.evaluations[evaluation_id] = updated_evaluation
            
            # Sauvegarder les changements
            self._save_evaluations()
            
            logger.info(f"Évaluation (ID: {evaluation_id}) mise à jour avec succès")
            return updated_evaluation
            
        except Exception as e:
            logger.error(f"Erreur lors de la mise à jour de l'évaluation: {str(e)}")
            return None
    
    def delete_evaluation(self, evaluation_id: str) -> bool:
        """
        Supprime une évaluation.
        
        Args:
            evaluation_id: Identifiant de l'évaluation à supprimer
            
        Returns:
            True si la suppression a réussi, False sinon
        """
        # Vérifier que l'évaluation existe
        if evaluation_id not in self.evaluations:
            logger.error(f"Évaluation avec ID {evaluation_id} non trouvée")
            return False
        
        try:
            # Supprimer l'évaluation de la collection
            del self.evaluations[evaluation_id]
            
            # Sauvegarder les changements
            self._save_evaluations()
            
            logger.info(f"Évaluation avec ID {evaluation_id} supprimée avec succès")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la suppression de l'évaluation: {str(e)}")
            return False
    
    def get_operator_evaluations(self, operator_id: str, period_start: Optional[datetime] = None, 
                               period_end: Optional[datetime] = None) -> List[PerformanceEvaluation]:
        """
        Récupère les évaluations d'un opérateur sur une période donnée.
        
        Args:
            operator_id: Identifiant de l'opérateur
            period_start: Date de début de la période (facultatif)
            period_end: Date de fin de la période (facultatif)
            
        Returns:
            Liste des évaluations de l'opérateur
        """
        filters = {"operator_id": operator_id}
        
        if period_start:
            filters["evaluated_after"] = period_start
            
        if period_end:
            filters["evaluated_before"] = period_end
            
        return self.get_evaluations(filters)
    
    def get_operation_evaluation(self, operation_id: str) -> Optional[PerformanceEvaluation]:
        """
        Récupère l'évaluation d'une opération spécifique.
        
        Args:
            operation_id: Identifiant de l'opération
            
        Returns:
            Évaluation de l'opération ou None si elle n'existe pas
        """
        evaluations = self.get_evaluations({"operation_id": operation_id})
        if evaluations:
            return evaluations[0]
        return None
    
    def generate_operator_summary(self, operator_id: str, period_start: Optional[datetime] = None, 
                                period_end: Optional[datetime] = None, 
                                operations_count: int = 0, 
                                operations_completed: int = 0) -> Optional[OperatorPerformanceSummary]:
        """
        Génère un résumé des performances d'un opérateur sur une période donnée.
        
        Args:
            operator_id: Identifiant de l'opérateur
            period_start: Date de début de la période (facultatif)
            period_end: Date de fin de la période (facultatif)
            operations_count: Nombre total d'opérations (facultatif)
            operations_completed: Nombre d'opérations terminées (facultatif)
            
        Returns:
            Résumé des performances ou None en cas d'erreur
        """
        try:
            # Utiliser les 6 derniers mois par défaut si aucune période n'est spécifiée
            if not period_start:
                period_start = datetime.now() - timedelta(days=180)
            
            if not period_end:
                period_end = datetime.now()
            
            # Récupérer les évaluations de l'opérateur
            evaluations = self.get_operator_evaluations(operator_id, period_start, period_end)
            
            # Générer le résumé
            summary = OperatorPerformanceSummary.from_evaluations(
                operator_id=operator_id,
                evaluations=evaluations,
                period_start=period_start,
                period_end=period_end,
                operations_count=operations_count,
                operations_completed=operations_completed
            )
            
            return summary
            
        except Exception as e:
            logger.error(f"Erreur lors de la génération du résumé de performance: {str(e)}")
            return None
    
    def generate_performance_report(self, params: Dict[str, Any]) -> Optional[PerformanceReport]:
        """
        Génère un rapport complet de performance.
        
        Args:
            params: Paramètres du rapport, incluant 'operator_id' ou 'operation_id'
            
        Returns:
            Rapport de performance ou None en cas d'erreur
        """
        try:
            operator_id = params.get("operator_id")
            operation_id = params.get("operation_id")
            
            if not operator_id and not operation_id:
                logger.error("Au moins l'identifiant de l'opérateur ou de l'opération est requis")
                return None
            
            # Définir la période
            period_start = params.get("period_start")
            if isinstance(period_start, str):
                period_start = datetime.fromisoformat(period_start.replace("Z", "+00:00"))
            elif not period_start:
                period_start = datetime.now() - timedelta(days=180)
                
            period_end = params.get("period_end")
            if isinstance(period_end, str):
                period_end = datetime.fromisoformat(period_end.replace("Z", "+00:00"))
            elif not period_end:
                period_end = datetime.now()
            
            # Générer un identifiant unique pour le rapport
            report_id = f"report-{uuid.uuid4().hex[:8]}"
            
            # Créer le titre du rapport
            title = params.get("title", "Rapport de performance")
            if not title:
                if operator_id:
                    title = f"Rapport de performance de l'opérateur {operator_id}"
                else:
                    title = f"Rapport de performance de l'opération {operation_id}"
                    
            # Initialiser le rapport
            report = PerformanceReport(
                id=report_id,
                title=title,
                generated_at=datetime.now(),
                period_start=period_start,
                period_end=period_end,
                operator_id=operator_id,
                operation_id=operation_id,
                summary={},
                evaluations=[],
                recommendations=[],
                charts_data={}
            )
            
            # Remplir le rapport selon le type (opérateur ou opération)
            if operator_id:
                # Récupérer les évaluations de l'opérateur
                evaluations = self.get_operator_evaluations(operator_id, period_start, period_end)
                
                # Récupérer les statistiques d'opérations si fournies
                operations_count = params.get("operations_count", 0)
                operations_completed = params.get("operations_completed", 0)
                
                # Générer le résumé de performance
                summary = self.generate_operator_summary(
                    operator_id=operator_id,
                    period_start=period_start,
                    period_end=period_end,
                    operations_count=operations_count,
                    operations_completed=operations_completed
                )
                
                if summary:
                    report.summary = summary.to_dict()
                    report.recommendations = summary.recommendations_summary
                
                # Ajouter les évaluations détaillées
                report.evaluations = [eval.to_dict() for eval in evaluations]
                
                # Préparer les données pour les graphiques
                if evaluations:
                    # Données pour le graphique d'évolution des scores
                    timeline_data = []
                    for eval in sorted(evaluations, key=lambda e: e.evaluated_at):
                        timeline_data.append({
                            "date": eval.evaluated_at.isoformat(),
                            "overall_score": eval.overall_score,
                            "evaluation_id": eval.id
                        })
                    
                    # Données pour le graphique radar des différents critères
                    radar_data = {}
                    for criteria in PerformanceCriteria:
                        scores = []
                        for eval in evaluations:
                            for score_entry in eval.scores:
                                if score_entry.criteria == criteria:
                                    scores.append(score_entry.score)
                        
                        if scores:
                            radar_data[criteria.value] = round(sum(scores) / len(scores), 1)
                    
                    # Ajouter les données des graphiques au rapport
                    report.charts_data = {
                        "timeline": timeline_data,
                        "radar": radar_data
                    }
            
            else:  # Rapport pour une opération spécifique
                # Récupérer l'évaluation de l'opération
                evaluation = self.get_operation_evaluation(operation_id)
                
                if evaluation:
                    # Ajouter les détails de l'évaluation
                    report.evaluations = [evaluation.to_dict()]
                    
                    # Ajouter le résumé (simplifié pour une seule opération)
                    report.summary = {
                        "scores": {score.criteria.value: score.score for score in evaluation.scores},
                        "overall_score": evaluation.overall_score,
                        "strengths": evaluation.strengths,
                        "areas_for_improvement": evaluation.areas_for_improvement
                    }
                    
                    report.recommendations = evaluation.recommendations
                    
                    # Données pour le graphique radar des différents critères
                    radar_data = {score.criteria.value: score.score for score in evaluation.scores}
                    
                    # Ajouter les données des graphiques au rapport
                    report.charts_data = {
                        "radar": radar_data
                    }
            
            # Ajouter le rapport à la collection
            self.reports[report.id] = report
            
            # Sauvegarder les changements
            self._save_reports()
            
            logger.info(f"Rapport de performance (ID: {report.id}) généré avec succès")
            return report
            
        except Exception as e:
            logger.error(f"Erreur lors de la génération du rapport de performance: {str(e)}")
            return None
    
    def get_report(self, report_id: str) -> Optional[PerformanceReport]:
        """
        Récupère un rapport par son identifiant.
        
        Args:
            report_id: Identifiant du rapport
            
        Returns:
            Rapport correspondant ou None s'il n'existe pas
        """
        return self.reports.get(report_id)
    
    def get_reports(self, filters: Optional[Dict[str, Any]] = None) -> List[PerformanceReport]:
        """
        Récupère les rapports selon les filtres spécifiés.
        
        Args:
            filters: Filtres à appliquer (facultatif)
            
        Returns:
            Liste des rapports correspondant aux filtres
        """
        if not filters:
            # Retourner tous les rapports
            return list(self.reports.values())
        
        result = []
        
        for report in self.reports.values():
            # Appliquer les filtres
            match = True
            
            # Filtre par opérateur
            if "operator_id" in filters and filters["operator_id"]:
                if report.operator_id != filters["operator_id"]:
                    match = False
            
            # Filtre par opération
            if "operation_id" in filters and filters["operation_id"]:
                if report.operation_id != filters["operation_id"]:
                    match = False
            
            # Filtre par date de génération (après)
            if "generated_after" in filters and filters["generated_after"]:
                generated_after = filters["generated_after"]
                if isinstance(generated_after, str):
                    generated_after = datetime.fromisoformat(generated_after.replace("Z", "+00:00"))
                
                if report.generated_at < generated_after:
                    match = False
            
            # Filtre par date de génération (avant)
            if "generated_before" in filters and filters["generated_before"]:
                generated_before = filters["generated_before"]
                if isinstance(generated_before, str):
                    generated_before = datetime.fromisoformat(generated_before.replace("Z", "+00:00"))
                
                if report.generated_at > generated_before:
                    match = False
            
            # Recherche dans le titre
            if "title" in filters and filters["title"]:
                if filters["title"].lower() not in report.title.lower():
                    match = False
            
            # Ajouter le rapport s'il correspond aux filtres
            if match:
                result.append(report)
        
        return result
    
    def delete_report(self, report_id: str) -> bool:
        """
        Supprime un rapport.
        
        Args:
            report_id: Identifiant du rapport à supprimer
            
        Returns:
            True si la suppression a réussi, False sinon
        """
        # Vérifier que le rapport existe
        if report_id not in self.reports:
            logger.error(f"Rapport avec ID {report_id} non trouvé")
            return False
        
        try:
            # Supprimer le rapport de la collection
            del self.reports[report_id]
            
            # Sauvegarder les changements
            self._save_reports()
            
            logger.info(f"Rapport avec ID {report_id} supprimé avec succès")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la suppression du rapport: {str(e)}")
            return False
